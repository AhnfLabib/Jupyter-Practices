{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0797aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression, make_classification, load_wine\n",
    "\n",
    "# --- Generate Data for Problem 1: Linear Regression ---\n",
    "X_reg, y_reg = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Generate Data for Problem 2: Imbalanced Classification ---\n",
    "# Create an imbalanced dataset (e.g., 2% fraud cases)\n",
    "X_imb, y_imb = make_classification(n_samples=1000, n_features=10, n_informative=5,\n",
    "                                   n_redundant=0, n_classes=2, weights=[0.98, 0.02],\n",
    "                                   flip_y=0, random_state=42)\n",
    "X_imb_train, X_imb_test, y_imb_train, y_imb_test = train_test_split(X_imb, y_imb, test_size=0.2, random_state=42, stratify=y_imb)\n",
    "\n",
    "\n",
    "# --- Generate Data for Problem 3 & 4: Standard Classification ---\n",
    "X_class, y_class = make_classification(n_samples=500, n_features=10, n_informative=5,\n",
    "                                       n_redundant=2, n_classes=3, random_state=42)\n",
    "# Make features have different scales for Problem 4\n",
    "X_class[:, 0] *= 100\n",
    "X_class[:, 3] *= 50\n",
    "X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Sample data generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e9210",
   "metadata": {},
   "source": [
    "**Problem 1: Linear Regression**\n",
    "\n",
    "A model to predict monthly sales revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a891c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Model Coefficient: 86.5115\n",
      "b) R^2 Score: 0.9450\n",
      "b) Mean Absolute Error (MAE): 16.0405\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# a) Train a Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_reg_train, y_reg_train)\n",
    "print(f\"a) Model Coefficient: {lin_reg.coef_[0]:.4f}\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = lin_reg.predict(X_reg_test)\n",
    "\n",
    "# b) Evaluate the model\n",
    "r2 = r2_score(y_reg_test, y_pred)\n",
    "mae = mean_absolute_error(y_reg_test, y_pred)\n",
    "print(f\"b) R^2 Score: {r2:.4f}\")\n",
    "print(f\"b) Mean Absolute Error (MAE): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f0043b",
   "metadata": {},
   "source": [
    "The model is **overfitting** because it performs well on training data but poorly on test data. To improve generalization, you can:\n",
    "1.  **Use Regularization:** Introduce a penalty for large coefficients to prevent the model from becoming too complex.\n",
    "    * **L1 (Lasso) Regularization:** Can shrink some coefficients to exactly zero, effectively performing feature selection.\n",
    "    * **L2 (Ridge) Regularization:** Shrinks coefficients but doesn't set them to zero. It's a good default choice.\n",
    "2.  **Get More Training Data:** A larger, more diverse dataset can help the model learn the underlying patterns better instead of memorizing noise.\n",
    "3.  **Feature Selection:** Remove irrelevant or redundant features that might be confusing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef7704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b) Logistic Regression Accuracy: 0.9800\n",
      "b) Linear SVM Accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# Problem 2: Fraud Detection\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# a) Train Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_imb_train, y_imb_train)\n",
    "log_reg_pred = log_reg.predict(X_imb_test)\n",
    "\n",
    "# a) Train Linear SVM\n",
    "linear_svm = SVC(kernel='linear', random_state=42)\n",
    "linear_svm.fit(X_imb_train, y_imb_train)\n",
    "svm_pred = linear_svm.predict(X_imb_test)\n",
    "\n",
    "# b) Compare accuracy\n",
    "log_reg_acc = accuracy_score(y_imb_test, log_reg_pred)\n",
    "svm_acc = accuracy_score(y_imb_test, svm_pred)\n",
    "\n",
    "print(f\"b) Logistic Regression Accuracy: {log_reg_acc:.4f}\")\n",
    "print(f\"b) Linear SVM Accuracy: {svm_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177d0bf",
   "metadata": {},
   "source": [
    "With only 2% of cases being fraudulent, **accuracy is a poor metric**. A model that always predicts \"not fraudulent\" would have 98% accuracy but be useless. To improve performance, you should:\n",
    "1.  **Change the Evaluation Metric:** Use metrics that are better for imbalanced data, such as **Precision**, **Recall**, **F1-Score**, or the **AUC-ROC curve**.\n",
    "2.  **Use Resampling Techniques:**\n",
    "    * **Oversampling:** Increase the number of minority class (fraud) samples. A common method is **SMOTE** (Synthetic Minority Over-sampling Technique), which creates new synthetic samples.\n",
    "    * **Undersampling:** Reduce the number of majority class (legitimate) samples.\n",
    "3.  **Set Class Weights:** Many models (including `LogisticRegression` and `SVC`) have a `class_weight='balanced'` parameter. This tells the model to pay more attention to the minority class during training by adjusting the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1c686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Accuracy with k=3: 0.4300\n",
      "b) Accuracy with k=50: 0.4900\n"
     ]
    }
   ],
   "source": [
    "# Problem 3: KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# a) Train a KNeighbors Classifier with k=3\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_3.fit(X_class_train, y_class_train)\n",
    "y_pred_3 = knn_3.predict(X_class_test)\n",
    "acc_3 = accuracy_score(y_class_test, y_pred_3)\n",
    "print(f\"a) Accuracy with k=3: {acc_3:.4f}\")\n",
    "\n",
    "# b) Increase k to 50\n",
    "knn_50 = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_50.fit(X_class_train, y_class_train)\n",
    "y_pred_50 = knn_50.predict(X_class_test)\n",
    "acc_50 = accuracy_score(y_class_test, y_pred_50)\n",
    "print(f\"b) Accuracy with k=50: {acc_50:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b10b8",
   "metadata": {},
   "source": [
    "A significant drop in test accuracy compared to training accuracy indicates **overfitting**.\n",
    "* **Cause:** In KNN, a small `k` (like 3) makes the model highly sensitive to noise in the training data, creating a very complex decision boundary. It essentially \"memorizes\" the training set.\n",
    "**How to fix:**\n",
    "    1.  **Increase `k`:** A larger `k` considers more neighbors, which smooths out the decision boundary and makes the model less complex and more generalized (as seen by the potential accuracy increase with k=50).\n",
    "    2.  **Use Cross-Validation:** Instead of guessing, use techniques like GridSearchCV to systematically test a range of `k` values and find the one that performs best on validation data.\n",
    "    3.  **Feature Scaling:** Ensure all features are on a similar scale. This is crucial for distance-based algorithms like KNN (see Problem 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce116fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Accuracy before normalization: 0.3600\n",
      "b) Accuracy after normalization: 0.8100\n"
     ]
    }
   ],
   "source": [
    "# Problem 4: Feature scaling\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# a) Train KNN on the original (unscaled) dataset\n",
    "knn_unscaled = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_unscaled.fit(X_class_train, y_class_train)\n",
    "y_pred_unscaled = knn_unscaled.predict(X_class_test)\n",
    "acc_unscaled = accuracy_score(y_class_test, y_pred_unscaled)\n",
    "print(f\"a) Accuracy before normalization: {acc_unscaled:.4f}\")\n",
    "\n",
    "# b) Apply StandardScaler to normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_class_train)\n",
    "X_test_scaled = scaler.transform(X_class_test) # Use the SAME scaler from training data\n",
    "\n",
    "# Retrain the model on scaled data\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_scaled.fit(X_train_scaled, y_class_train)\n",
    "y_pred_scaled = knn_scaled.predict(X_test_scaled)\n",
    "acc_scaled = accuracy_score(y_class_test, y_pred_scaled)\n",
    "print(f\"b) Accuracy after normalization: {acc_scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ad213",
   "metadata": {},
   "source": [
    "No, **Decision Trees would not benefit from feature scaling**.\n",
    "* **Why:** Decision trees work by splitting data based on feature thresholds (e.g., `if feature_A > 5.3`). The scale of the feature does not matter; only the relative ordering of the values within that feature matters. Scaling a feature (e.g., multiplying it by 10) will not change the order of its values, so the optimal split point remains the same. The algorithm is not based on distance calculations like KNN or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e148c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Gaussian Naïve Bayes Test Accuracy: 1.0000\n",
      "b) Logistic Regression Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Problem 5: Naive Bayes vs Logistic Regression\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# a) Load data and train Gaussian Naïve Bayes\n",
    "wine = load_wine()\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=42)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_wine_train, y_wine_train)\n",
    "gnb_pred = gnb.predict(X_wine_test)\n",
    "gnb_acc = accuracy_score(y_wine_test, gnb_pred)\n",
    "print(f\"a) Gaussian Naïve Bayes Test Accuracy: {gnb_acc:.4f}\")\n",
    "\n",
    "# b) Train Logistic Regression\n",
    "log_reg_wine = LogisticRegression(max_iter=10000, random_state=42) # Increased max_iter for convergence\n",
    "log_reg_wine.fit(X_wine_train, y_wine_train)\n",
    "log_reg_wine_pred = log_reg_wine.predict(X_wine_test)\n",
    "log_reg_acc = accuracy_score(y_wine_test, log_reg_wine_pred)\n",
    "print(f\"b) Logistic Regression Test Accuracy: {log_reg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b0bfc6",
   "metadata": {},
   "source": [
    "One model might perform better than the other due to their underlying assumptions:\n",
    "* **Gaussian Naïve Bayes** assumes that all features are **conditionally independent** given the class. This is a \"naïve\" and often incorrect assumption. If the features in the Wine dataset are correlated (e.g., color intensity and alcohol content), Naïve Bayes may not perform as well. However, it can work very well even when the assumption is violated, especially with limited data.\n",
    "* **Logistic Regression** does not assume feature independence. It learns a linear relationship between the features and the log-odds of the outcome. If the decision boundary between the wine classes is roughly linear, Logistic Regression is likely to perform very well. In this case, it appears the features are not perfectly independent, giving a slight edge to Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df7603",
   "metadata": {},
   "source": [
    "**Problem 6: LR vs KNN for hiring candidates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8a41b",
   "metadata": {},
   "source": [
    "a) For predicting if a candidate will be hired, **Logistic Regression would generally be a better choice**.\n",
    "* **Interpretability:** Logistic Regression is highly interpretable. You can examine the model's coefficients to understand how much each feature (work experience, education) contributes to the hiring decision, which is valuable for business insights.\n",
    "* **Performance:** It's computationally fast, both for training and prediction.\n",
    "* **Simplicity:** It's less sensitive to irrelevant features and doesn't require tuning hyperparameters like `k` in KNN.\n",
    "\n",
    "KNN is less suitable because it can be slow with large datasets, requires feature scaling, and doesn't provide a clear model of *why* a prediction was made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24299793",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8d780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
